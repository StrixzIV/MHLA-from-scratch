{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2364b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from tokenizers import Tokenizer, models, pre_tokenizers, decoders, trainers\n",
    "\n",
    "import model\n",
    "\n",
    "from chat import save_checkpoint, load_checkpoint\n",
    "from model import GPTLanguageModel, learning_rate, max_iters, eval_interval, eval_iters, device, block_size, batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c07ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer.from_file(\"./tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464941e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.9\n",
    "data = text2tensor(text)\n",
    "\n",
    "model.vocab_size = tokenizer.get_vocab_size()\n",
    "\n",
    "n = int(train_size * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe5407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = GPTLanguageModel()\n",
    "m = m.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd06ee06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x.to(device), y.to(device)\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "\n",
    "    out = {}\n",
    "    m.eval()\n",
    "    \n",
    "    for split in ['train', 'val']:\n",
    "    \n",
    "        losses = torch.zeros(eval_iters)\n",
    "    \n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = m(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "    \n",
    "        out[split] = losses.mean()\n",
    "    \n",
    "    m.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b642c2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=learning_rate)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769971d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURATION ---\n",
    "resume_training = False  # Set to True if continuing from a previous run/dataset\n",
    "checkpoint_path = \"model_checkpoint.pth\"\n",
    "best_model_path = \"best_model.pth\"\n",
    "best_val_loss = float('inf')\n",
    "start_iter = 0\n",
    "\n",
    "if resume_training:\n",
    "    start_iter = load_checkpoint(checkpoint_path, m, optimizer)\n",
    "\n",
    "print(f\"Starting training from iteration {start_iter}...\")\n",
    "\n",
    "for iter in range(start_iter, max_iters):\n",
    "\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "        \n",
    "        if losses['val'] < best_val_loss:\n",
    "            best_val_loss = losses['val']\n",
    "            save_checkpoint(iter, m, optimizer, losses['val'], best_model_path)\n",
    "            print(f\"   (New best model saved!)\")\n",
    "\n",
    "        save_checkpoint(iter, m, optimizer, losses['val'], checkpoint_path)\n",
    "\n",
    "    xb, yb = get_batch('train')\n",
    "    \n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130b378d",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = m.state_dict()\n",
    "torch.save(state, './models/final.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
